# ЛР 1. Алгоритмы сортировки

## Задача 1: алгоритм сортировки 1
Дан массив из чисел (как ```std::vector<T>```). Реализовать сортировку, чтобы в среднем она работала быстрее чем за $O(N^2)$.

Для реализации сортировки был выбран quick sort по ряду причин: относительно просто реализовать и работает менее чем за $O(N^2)$

Оценим время работы. Имеем массив длинной $N$. Алгоритм работает следующим образом: берётся опорный элемент (можно взять первый элемент массива), далее при проходе по всему массиву он разделяется на два: элементы, которые меньше опорного и те, которые больше. Далее эти два массива сортируются рекуррентно и соединяются: меньший массив + опорный элемент + больший массив. На выходе получаем отсортированный массив.

Оценим сложность работы по мастер-теореме. На каждом вызове массив делится на две части и вызывается дважды. Также на каждый уровень вложения $i$ требуется $O\left(\frac{N}{2^i}\right)$ дополнительных затрат. Итого получим общую асимптотическую сложность: $$T(N) = 2 T\left(\frac{N}{2}\right) + O(N)$$

То есть $a = 2, b = 2, c = 1$ и $c = \log_a b$, тогда $T(N) = O(N \log_2N)$. В худшем же случае может оказаться, что все элементы будут больше (или меньше) опорного, и так будет продолжаться далее, тогда асимптотическая сложность порядка $O(N^2)$

Оценка по памяти: той же мастер теоремой: $a = 2, b = 2, c = 0$: $0 < \log_22 = 1 \Rightarrow T(N) = O(N)$

## Задача 2: алгоритм сортировки 2
Задача аналогична, только теперь необходимо, чтобы алгоритм работал за $O(N\log_2N)$ **всегда**, также, чтобы реализация была по ёмкостной сложности была лучше.

Для такой задачи отлично подходит сортировка кучей. Аналогично выводится асимптотическая сложность вычислений $O(N\log_2 N)$. По памяти же этот алгоритм занимает $O(1)$, так как во время работы не создаются дополнительные массивы, напрямую изменяется данный массив.